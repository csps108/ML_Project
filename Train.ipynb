{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本Code執行Model training\n",
    "* images_0為0_images.npy的路徑\n",
    "* labels_0為0_labels_hot.npy的路徑\n",
    "* 以此類推。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.python.keras.optimizers import SGD,RMSprop\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 路徑檔名要改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "images_all=[]\n",
    "labels_all=[]\n",
    "#Read cat npy file\n",
    "images_0=np.load('C:\\\\Users\\\\Administrator\\\\Desktop\\\\yilin\\\\temp\\\\0_images.npy')\n",
    "images_all=images_0\n",
    "labels_0=np.load('C:\\\\Users\\\\Administrator\\\\Desktop\\\\yilin\\\\temp\\\\0_labels_hot.npy')\n",
    "labels_all=labels_0\n",
    "#Read dog npy file\n",
    "images_1=np.load('C:\\\\Users\\\\Administrator\\\\Desktop\\\\yilin\\\\temp\\\\1_images.npy')\n",
    "images_all=np.append(images_all,images_1,axis=0)\n",
    "labels_1=np.load('C:\\\\Users\\\\Administrator\\\\Desktop\\\\yilin\\\\temp\\\\1_labels_hot.npy')\n",
    "labels_all=np.append(labels_all,labels_1,axis=0)\n",
    "\n",
    "images_2=np.load('C:\\\\Users\\\\Administrator\\\\Desktop\\\\yilin\\\\temp\\\\2_images.npy')\n",
    "images_all=np.append(images_all,images_2,axis=0)\n",
    "labels_2=np.load('C:\\\\Users\\\\Administrator\\\\Desktop\\\\yilin\\\\temp\\\\2_labels_hot.npy')\n",
    "labels_all=np.append(labels_all,labels_2,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_one_hot = np.zeros([labels_all.size, np.amax(labels_all)+1])\n",
    "y_one_hot[np.arange(labels_all.size), labels_all.reshape(1, labels_all.size)]  = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 架構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate model\n",
    "model = Sequential()\n",
    "# input: 190x190 images with 3 channels -> (224, 224, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(224,224,3),padding='same',name='block1_conv2_1'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',padding='same',name='block1_conv2_2'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),name='block1_MaxPooling'))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu',padding='same',name='block2_conv2_1'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu',padding='same',name='block2_conv2_2'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),name='block2_MaxPooling'))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu',padding='same',name='block3_conv2_1'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu',padding='same',name='block3_conv2_2'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu',padding='same',name='block3_conv2_3'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu',padding='same',name='block3_conv2_4'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu',padding='same',name='block3_conv2_5'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),name='block3_MaxPooling'))\n",
    "\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation='relu',padding='same',name='block4_conv2_1'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu',padding='same',name='block4_conv2_2'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu',padding='same',name='block4_conv2_3'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu',padding='same',name='block4_conv2_4'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu',padding='same',name='block4_conv2_5'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),name='block4_MaxPooling'))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation='relu',padding='same',name='block5_conv2_1'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu',padding='same',name='block5_conv2_2'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu',padding='same',name='block5_conv2_3'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu',padding='same',name='block5_conv2_4'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),name='block5_MaxPooling'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu',name='final_output_1'))\n",
    "model.add(Dense(4096, activation='relu',name='final_output_2'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax',name='class_output'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv2_1 (Conv2D)      (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2_2 (Conv2D)      (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_MaxPooling (MaxPoolin (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv2_1 (Conv2D)      (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2_2 (Conv2D)      (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_MaxPooling (MaxPoolin (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv2_1 (Conv2D)      (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2_2 (Conv2D)      (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv2_3 (Conv2D)      (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv2_4 (Conv2D)      (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv2_5 (Conv2D)      (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_MaxPooling (MaxPoolin (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv2_1 (Conv2D)      (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2_2 (Conv2D)      (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv2_3 (Conv2D)      (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv2_4 (Conv2D)      (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv2_5 (Conv2D)      (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_MaxPooling (MaxPoolin (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv2_1 (Conv2D)      (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2_2 (Conv2D)      (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2_3 (Conv2D)      (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2_4 (Conv2D)      (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_MaxPooling (MaxPoolin (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "final_output_1 (Dense)       (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "final_output_2 (Dense)       (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "class_output (Dense)         (None, 3)                 12291     \n",
      "=================================================================\n",
      "Total params: 142,532,419\n",
      "Trainable params: 142,532,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 fold Cross Validation\n",
    "* kf=KFold(n_splits=5,shuffle=True)----->執行5folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " 2/59 [>.............................] - ETA: 10s - loss: 1.1026 - accuracy: 0.3070WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1120s vs `on_train_batch_end` time: 0.2551s). Check your callbacks.\n",
      "59/59 [==============================] - 23s 382ms/step - loss: 1.0831 - accuracy: 0.4385\n",
      "Epoch 2/15\n",
      "59/59 [==============================] - 22s 373ms/step - loss: 1.0508 - accuracy: 0.4493\n",
      "Epoch 3/15\n",
      "59/59 [==============================] - 22s 375ms/step - loss: 1.0989 - accuracy: 0.3840\n",
      "Epoch 4/15\n",
      "59/59 [==============================] - 22s 376ms/step - loss: 1.0916 - accuracy: 0.4830\n",
      "Epoch 5/15\n",
      "59/59 [==============================] - 22s 377ms/step - loss: 1.0702 - accuracy: 0.4833\n",
      "Epoch 6/15\n",
      "59/59 [==============================] - 22s 378ms/step - loss: 1.0506 - accuracy: 0.4965\n",
      "Epoch 7/15\n",
      "59/59 [==============================] - 22s 378ms/step - loss: 1.0741 - accuracy: 0.5339\n",
      "Epoch 8/15\n",
      "59/59 [==============================] - 22s 378ms/step - loss: 0.9808 - accuracy: 0.4977\n",
      "Epoch 9/15\n",
      "59/59 [==============================] - 22s 379ms/step - loss: 0.7509 - accuracy: 0.6389\n",
      "Epoch 10/15\n",
      "59/59 [==============================] - 22s 380ms/step - loss: 0.6587 - accuracy: 0.6876\n",
      "Epoch 11/15\n",
      "59/59 [==============================] - 22s 380ms/step - loss: 0.6216 - accuracy: 0.7159\n",
      "Epoch 12/15\n",
      "59/59 [==============================] - 22s 381ms/step - loss: 0.5859 - accuracy: 0.7262\n",
      "Epoch 13/15\n",
      "59/59 [==============================] - 22s 380ms/step - loss: 0.6052 - accuracy: 0.7075\n",
      "Epoch 14/15\n",
      "59/59 [==============================] - 22s 381ms/step - loss: 0.5557 - accuracy: 0.7451\n",
      "Epoch 15/15\n",
      "59/59 [==============================] - 22s 380ms/step - loss: 0.5283 - accuracy: 0.7647\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 0.7420 - accuracy: 0.7076\n",
      "accuracy: 70.76%\n",
      "Epoch 1/15\n",
      " 2/59 [>.............................] - ETA: 19s - loss: 0.5442 - accuracy: 0.7105WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1120s vs `on_train_batch_end` time: 0.2805s). Check your callbacks.\n",
      "59/59 [==============================] - 22s 381ms/step - loss: 0.5424 - accuracy: 0.7574\n",
      "Epoch 2/15\n",
      "59/59 [==============================] - 22s 381ms/step - loss: 0.5325 - accuracy: 0.7641\n",
      "Epoch 3/15\n",
      "59/59 [==============================] - 23s 382ms/step - loss: 0.5227 - accuracy: 0.7662\n",
      "Epoch 4/15\n",
      "59/59 [==============================] - 23s 382ms/step - loss: 0.4928 - accuracy: 0.7764\n",
      "Epoch 5/15\n",
      "59/59 [==============================] - 23s 381ms/step - loss: 0.4993 - accuracy: 0.7794\n",
      "Epoch 6/15\n",
      "59/59 [==============================] - 23s 382ms/step - loss: 0.4869 - accuracy: 0.7821\n",
      "Epoch 7/15\n",
      "59/59 [==============================] - 23s 382ms/step - loss: 0.4937 - accuracy: 0.7815\n",
      "Epoch 8/15\n",
      "59/59 [==============================] - 23s 382ms/step - loss: 0.4688 - accuracy: 0.7969\n",
      "Epoch 9/15\n",
      "59/59 [==============================] - 23s 382ms/step - loss: 0.4604 - accuracy: 0.7984\n",
      "Epoch 10/15\n",
      "59/59 [==============================] - 23s 384ms/step - loss: 0.4535 - accuracy: 0.8041\n",
      "Epoch 11/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.4341 - accuracy: 0.8095\n",
      "Epoch 12/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.4383 - accuracy: 0.8119\n",
      "Epoch 13/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.4109 - accuracy: 0.8206\n",
      "Epoch 14/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.4050 - accuracy: 0.8221\n",
      "Epoch 15/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.4064 - accuracy: 0.8279\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 0.5951 - accuracy: 0.7401\n",
      "accuracy: 74.01%\n",
      "Epoch 1/15\n",
      " 2/59 [>.............................] - ETA: 18s - loss: 0.4881 - accuracy: 0.8158WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1093s vs `on_train_batch_end` time: 0.2783s). Check your callbacks.\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.4193 - accuracy: 0.8173\n",
      "Epoch 2/15\n",
      "59/59 [==============================] - 23s 384ms/step - loss: 0.3967 - accuracy: 0.8291\n",
      "Epoch 3/15\n",
      "59/59 [==============================] - 23s 384ms/step - loss: 0.3910 - accuracy: 0.8303\n",
      "Epoch 4/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.3819 - accuracy: 0.8333\n",
      "Epoch 5/15\n",
      "59/59 [==============================] - 23s 384ms/step - loss: 0.3632 - accuracy: 0.8417\n",
      "Epoch 6/15\n",
      "59/59 [==============================] - 23s 384ms/step - loss: 0.3699 - accuracy: 0.8351\n",
      "Epoch 7/15\n",
      "59/59 [==============================] - 23s 384ms/step - loss: 0.3485 - accuracy: 0.8519\n",
      "Epoch 8/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.3244 - accuracy: 0.8619\n",
      "Epoch 9/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.3142 - accuracy: 0.8586\n",
      "Epoch 10/15\n",
      "59/59 [==============================] - 23s 384ms/step - loss: 0.3241 - accuracy: 0.8589\n",
      "Epoch 11/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.3022 - accuracy: 0.8688\n",
      "Epoch 12/15\n",
      "59/59 [==============================] - 23s 384ms/step - loss: 0.2884 - accuracy: 0.8742\n",
      "Epoch 13/15\n",
      "59/59 [==============================] - 23s 384ms/step - loss: 0.2770 - accuracy: 0.8841\n",
      "Epoch 14/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.2679 - accuracy: 0.8820\n",
      "Epoch 15/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.2871 - accuracy: 0.8814\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 0.6031 - accuracy: 0.7714\n",
      "accuracy: 77.14%\n",
      "Epoch 1/15\n",
      " 2/59 [>.............................] - ETA: 18s - loss: 0.3500 - accuracy: 0.8684WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1100s vs `on_train_batch_end` time: 0.2656s). Check your callbacks.\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.3036 - accuracy: 0.8754\n",
      "Epoch 2/15\n",
      "59/59 [==============================] - 23s 384ms/step - loss: 0.2563 - accuracy: 0.8932\n",
      "Epoch 3/15\n",
      "59/59 [==============================] - 23s 384ms/step - loss: 0.2558 - accuracy: 0.8899\n",
      "Epoch 4/15\n",
      "59/59 [==============================] - 23s 384ms/step - loss: 0.2450 - accuracy: 0.8986\n",
      "Epoch 5/15\n",
      "59/59 [==============================] - 23s 384ms/step - loss: 0.2186 - accuracy: 0.9061\n",
      "Epoch 6/15\n",
      "59/59 [==============================] - 23s 385ms/step - loss: 0.2130 - accuracy: 0.9127\n",
      "Epoch 7/15\n",
      "59/59 [==============================] - 23s 386ms/step - loss: 0.1905 - accuracy: 0.9178\n",
      "Epoch 8/15\n",
      "59/59 [==============================] - 23s 384ms/step - loss: 0.2004 - accuracy: 0.9139\n",
      "Epoch 9/15\n",
      "59/59 [==============================] - 23s 384ms/step - loss: 0.1710 - accuracy: 0.9293\n",
      "Epoch 10/15\n",
      "59/59 [==============================] - 23s 384ms/step - loss: 0.1679 - accuracy: 0.9275\n",
      "Epoch 11/15\n",
      "59/59 [==============================] - 23s 384ms/step - loss: 0.2172 - accuracy: 0.9019\n",
      "Epoch 12/15\n",
      "59/59 [==============================] - 23s 384ms/step - loss: 0.1567 - accuracy: 0.9293\n",
      "Epoch 13/15\n",
      "59/59 [==============================] - 23s 384ms/step - loss: 0.1479 - accuracy: 0.9374\n",
      "Epoch 14/15\n",
      "59/59 [==============================] - 23s 384ms/step - loss: 0.2075 - accuracy: 0.9139\n",
      "Epoch 15/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.1145 - accuracy: 0.9509\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 0.2876 - accuracy: 0.9001\n",
      "accuracy: 90.01%\n",
      "Epoch 1/15\n",
      " 2/59 [>.............................] - ETA: 18s - loss: 0.1460 - accuracy: 0.9386WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1143s vs `on_train_batch_end` time: 0.2600s). Check your callbacks.\n",
      "59/59 [==============================] - 24s 399ms/step - loss: 0.1725 - accuracy: 0.9323\n",
      "Epoch 2/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.1848 - accuracy: 0.9278\n",
      "Epoch 3/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.1351 - accuracy: 0.9428\n",
      "Epoch 4/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.1568 - accuracy: 0.9317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.1046 - accuracy: 0.9513\n",
      "Epoch 6/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.0877 - accuracy: 0.9600\n",
      "Epoch 7/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.1410 - accuracy: 0.9350\n",
      "Epoch 8/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.0893 - accuracy: 0.9603\n",
      "Epoch 9/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.0794 - accuracy: 0.9636\n",
      "Epoch 10/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.0893 - accuracy: 0.9627\n",
      "Epoch 11/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.0551 - accuracy: 0.9753\n",
      "Epoch 12/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.0889 - accuracy: 0.9621\n",
      "Epoch 13/15\n",
      "59/59 [==============================] - 23s 382ms/step - loss: 0.1144 - accuracy: 0.9567\n",
      "Epoch 14/15\n",
      "59/59 [==============================] - 23s 383ms/step - loss: 0.0956 - accuracy: 0.9636\n",
      "Epoch 15/15\n",
      "59/59 [==============================] - 23s 382ms/step - loss: 0.0919 - accuracy: 0.9615\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.1714 - accuracy: 0.9349\n",
      "accuracy: 93.49%\n",
      "Accuracy: 81.08% (+/- 9.01%)\n",
      "Sensitivity 0.81% (+/- 0.09%)\n",
      "Specificity 0.91% (+/- 0.05%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf=KFold(n_splits=5,shuffle=True)\n",
    "cvscores = []\n",
    "cvsen=[]\n",
    "cvspe=[]\n",
    "for train,test in kf.split(images_all,y_one_hot):\n",
    "    model.fit(images_all[train], y_one_hot[train], epochs=15, batch_size=57, verbose=1)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(images_all[test], y_one_hot[test], verbose=1)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    pre_sen=model.predict(images_all[test])\n",
    "    ##############class report################################\n",
    "    for i in range(len(pre_sen)):\n",
    "        max_value=max(pre_sen[i])\n",
    "        for j in range(len(pre_sen[i])):\n",
    "            if max_value==pre_sen[i][j]:\n",
    "                pre_sen[i][j]=1\n",
    "            else:\n",
    "                pre_sen[i][j]=0\n",
    "    from sklearn.metrics import classification_report\n",
    "    label2index={'NO DR':0,'Moderate DR':1,'Severe DR':2}\n",
    "    res=(classification_report(y_one_hot[test],pre_sen,target_names=label2index,digits=4))\n",
    "    print(res)\n",
    "    ################Kappa#################################################\n",
    "    from sklearn.metrics import cohen_kappa_score,confusion_matrix\n",
    "    kappa = cohen_kappa_score(y_one_hot[test].argmax(axis=1),pre_sen.argmax(axis=1),weights='quadratic')\n",
    "    print(kappa)\n",
    "    ###############confusion matrix#####################################\n",
    "    import seaborn as sns\n",
    "    import  matplotlib.pyplot as plt\n",
    "    cm=confusion_matrix(y_one_hot[test].argmax(axis=1),pre_sen.argmax(axis=1))\n",
    "    LABELS=['NO DR','Moderate DR','Severe DR']\n",
    "    cmn = cm.astype('float')/cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    sns.heatmap(cmn, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\".2f\");\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel('True class')\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.show()\n",
    "    ######################################################################\n",
    "    m=tensorflow.python.keras.metrics.SensitivityAtSpecificity(0.5)\n",
    "    m.update_state(y_one_hot[test],pre_sen)\n",
    "    mm=m.result().numpy()\n",
    "    mmm = tensorflow.python.keras.metrics.SpecificityAtSensitivity(0.5)\n",
    "    mmm.update_state(y_one_hot[test],pre_sen)\n",
    "    mmmm=mmm.result().numpy()\n",
    "    cvsen.append(mm)\n",
    "    cvspe.append(mmmm)\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"Accuracy: %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "print(\"Sensitivity %.2f%% (+/- %.2f%%)\" % (np.mean(cvsen)*100, np.std(cvsen)*100))\n",
    "print(\"Specificity %.2f%% (+/- %.2f%%)\" % (np.mean(cvspe)*100, np.std(cvspe)*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.08% (+/- 9.01%)\n",
      "Sensitivity 81.08% (+/- 9.01%)\n",
      "Specificity 90.54% (+/- 4.51%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "print(\"Sensitivity %.2f%% (+/- %.2f%%)\" % (np.mean(cvsen)*100, np.std(cvsen)*100))\n",
    "print(\"Specificity %.2f%% (+/- %.2f%%)\" % (np.mean(cvspe)*100, np.std(cvspe)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
